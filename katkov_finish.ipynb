{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовое задание:\n",
    "# Сделать простой cashflow отчёт на основании данных полученных через Plaid из банка Bank of Amerika \n",
    "# (использовать тестовые реквизиты от самого plaid). Для получения данных из банка использовать сервис \n",
    "# https://plaid.com/eu/ (он бесплатен для тестирования).\n",
    "\n",
    "# Пример “простого cashflow” (это разбвки income/expenses по категориям и по месяцам): \n",
    "# https://www.dropbox.com/s/lywnj7f1fchukkg/Screenshot%202020-05-24%2013.43.08.png?dl=0\n",
    "\n",
    "# В качестве результата выполнения задания нужно предоставить:\n",
    "# 1) ссылка на документ в google spreadsheets с 2 листами:\n",
    "#   - лист с “сырыми данными” по транзакциям из plaid. \n",
    "#   - лист с cashflow отчётам, который построен по аналогии с примером со скриншота.\n",
    "# 2) ссылку на репозиторий с кодом, который был использован для получения данных через plaid и \n",
    "# сохранения в google spreadsheets\n",
    "\n",
    "# Результаты выполнения нужно отправить через эту форму: https://airtable.com/shra9dmxAXr5D67Lu\n",
    "\n",
    "# Срок выполнения: результаты выполнения задания нужно отправить не позднее 4 июня\n",
    "\n",
    "# Комментарии к заданию:\n",
    "# - Нам важно понять насколько ты владеешь python для решения базовых задач по извлечению, сохранению и \n",
    "# обработке данных из сторонних систем.\n",
    "# - Если не сможешь выполнить всё задание, но выполнишь его часть, то всё равно можешь прислать результаты. \n",
    "# Задание построено так, что имеет несколько частей, которые различаются по сложности. Поэтому, выполнив \n",
    "# даже часть задания, ты покажешь то, что умеешь. Используй поле “Комментарии к результату” в форме для того, \n",
    "# чтобы дать пояснения о том, что удалось сделать, а что нет.\n",
    "# - Задавать вопросы и уточнять задание можно в этом чате."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request & data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request.status_code 200\n"
     ]
    }
   ],
   "source": [
    "# plaid.com/docs/retrieve-transactions-request\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "PLAID_CLIENT_ID='5f01a56a00f5020011f9c2fd'\n",
    "PLAID_SECRET='49eedfa156db01d6674fc99b2f9fb0'\n",
    "PLAID_PUBLIC_KEY='9908c5c8242c1da1e39a2f8f0ca758'\n",
    "PLAID_PRODUCTS='transactions'\n",
    "PLAID_COUNTRY_CODES='US'\n",
    "\n",
    "url1 = 'https://sandbox.plaid.com/transactions/get'\n",
    "payload = {'client_id':PLAID_CLIENT_ID,\n",
    "        'secret':PLAID_SECRET,\n",
    "        \"access_token\":\"access-sandbox-5f8a3c5a-38e9-4283-abca-6dea9d11695c\",\n",
    "        #'institution_id': 'ins_1'\n",
    "        #'institution_name': 'Bank of America',\n",
    "        'start_date':'2001-01-01',\n",
    "        'end_date': '2020-06-01',\n",
    "        #'count': 250,\n",
    "        #'offset': 0,\n",
    "                         \n",
    "                        }\n",
    "headers = {'Content-Type': 'application/json',}\n",
    "request = requests.post(url1, \n",
    "                   json={\"key\": \"value\"}, \n",
    "                   auth=('user_good', 'pass_good'),\n",
    "                   data=json.dumps(payload), headers=headers)\n",
    "print('request.status_code', request.status_code)\n",
    "\n",
    "df = pd.DataFrame(pd.json_normalize(json.loads(request.text)['transactions']))\n",
    "#df[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-stas/.local/lib/python3.7/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/tljh/user/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "def date_prep(df1):\n",
    "    \"\"\"\n",
    "    take features from a date\n",
    "    \"\"\"\n",
    "    data = df1.copy()\n",
    "    dt_col = 'date'\n",
    "    data[dt_col] = pd.to_datetime(data[dt_col])\n",
    "    attrs = [\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "    ]\n",
    "    \n",
    "    month_str = {'1': 'Yan',\n",
    "        '2': 'Feb',\n",
    "        '3': 'Mar',\n",
    "        '4': 'Apr',\n",
    "        '5': 'May',\n",
    "        '6': 'Jun',\n",
    "        '7': 'Jul',\n",
    "        '8': 'Auv',\n",
    "        '9': 'Sep',\n",
    "        '10': 'Okt',\n",
    "        '11': 'Nov',\n",
    "        '12': 'Dec'\n",
    "    }\n",
    "    for attr in attrs:\n",
    "        data[attr] = getattr(data[dt_col].dt, attr).astype(int)\n",
    "    data = data.sort_values(by=['year', 'month'])\n",
    "    data['month_str'] = data['month'].astype(str)\n",
    "    data['month_str'] = data['month_str'].map(month_str)\n",
    "    data['year_str'] = data['year'].astype(str)\n",
    "    data['date'] = data['month_str'] + ' ' + data['year_str']\n",
    "    return data\n",
    "\n",
    "def prep_category(df1):\n",
    "    \"\"\"\n",
    "    some preproccesing features\n",
    "    \"\"\"\n",
    "    df = df1.copy()\n",
    "    df['category'] = df['category'].str.join(',')    \n",
    "    df['flow_direct'] = 'Expense'\n",
    "    df['flow_direct'][df.amount<0] = 'Income'\n",
    "    df['amount'] = df['amount']*(-1)\n",
    "    df['merchant_name'] = df['merchant_name'].fillna('Missing_value')\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_total(df1):\n",
    "    \"\"\"\n",
    "    create addition rows - total values for category & merchant_name\n",
    "    and then takes them in pivot table\n",
    "    \"\"\"\n",
    "    df = df1.copy()\n",
    "    zz = pd.DataFrame(df1.groupby([\"category\",'date'])['amount'].sum())\n",
    "    zz['merchant_name'] = 'total'\n",
    "    zz['flow_direct'] = 'Expense'\n",
    "    zz['category']=''\n",
    "    zz['date']=''\n",
    "    for ii in range(len(zz)):\n",
    "        zz['category'].iloc[ii] = zz.index[ii][0]\n",
    "        zz['date'].iloc[ii] = zz.index[ii][1]\n",
    "        if zz.category.iloc[ii] in df1.category[df1.flow_direct=='Income'].unique():\n",
    "            zz['flow_direct'].iloc[ii] = 'Income'\n",
    "\n",
    "    czz = pd.DataFrame(df1.groupby([\"flow_direct\",'date'])['amount'].sum())\n",
    "    czz['category'] = 'total'\n",
    "    czz['merchant_name'] = ''\n",
    "    czz['flow_direct'] = ''\n",
    "    czz['date']=''\n",
    "    for ii in range(len(czz)):\n",
    "        czz['flow_direct'].iloc[ii] = czz.index[ii][0]\n",
    "        czz['date'].iloc[ii] = czz.index[ii][1]\n",
    "    df2 = pd.concat([df1, zz, czz], ignore_index=True)\n",
    "    return df2\n",
    "\n",
    "# create dataframe after ETL\n",
    "df1 = date_prep(prep_category(df))[['flow_direct', 'category', \n",
    "                                    'merchant_name',  'date',  'amount', ]] # 'year', 'month',\n",
    "#df1[:3]\n",
    "\n",
    "# create total rows for categories\n",
    "df2 = create_total(df1)\n",
    "# create output pivot table\n",
    "qqq = df2.pivot_table('amount', ['flow_direct', 'category', 'merchant_name'], 'date', dropna=True, \n",
    "                      aggfunc='sum', margins_name='Grand total', margins=True)\n",
    "qqq= qqq.fillna(0)\n",
    "\n",
    "# transform multi-index pivot table to dataframe columns\n",
    "qqq['expense/income'] = ''\n",
    "qqq['category1'] = ''\n",
    "qqq['category2'] = ''\n",
    "\n",
    "for ii in range(len(qqq.index)):\n",
    "    qqq['expense/income'].iloc[ii] = qqq.index[ii][0]\n",
    "    qqq['category1'].iloc[ii] = qqq.index[ii][1]\n",
    "    qqq['category2'].iloc[ii] = qqq.index[ii][2]\n",
    "flow_list = qqq['expense/income'].unique()\n",
    "cat1_list = qqq['category1'].unique()\n",
    "cat2_list = qqq['category2'].unique()\n",
    "\n",
    "def trans_qqq(qqq, col, col_list, qqq_index):\n",
    "    ilist=0\n",
    "    for ii in range(len(qqq_index)):\n",
    "        if qqq[col].iloc[ii]=='total':\n",
    "            ii +=1\n",
    "        else:\n",
    "            if (qqq[col].iloc[ii]==col_list[ilist]):\n",
    "                ilist+=1\n",
    "            else:\n",
    "                qqq[col].iloc[ii]=''\n",
    "    return qqq[col]\n",
    "\n",
    "qqq['expense/income'] = trans_qqq(qqq, 'expense/income', flow_list, qqq.index)\n",
    "qqq['category1'] = trans_qqq(qqq, 'category1', cat1_list, qqq.index)\n",
    "\n",
    "# create structure for output dataframe\n",
    "outdataframe = pd.DataFrame(columns = ['expense/income', 'category1', 'category2', \n",
    "                                      'Nov 2019','Dec 2019','Yan 2020', \n",
    "                                      'Feb 2020','Mar 2020','Apr 2020',\n",
    "                                       'May 2020','Grand total'])\n",
    "outdataframe = pd.concat([outdataframe, qqq], ignore_index=True)\n",
    "#outdataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet 'Output_data' id:460162027>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data uploading to google spreadsheet\n",
    "from df2gspread import df2gspread as d2g\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import httplib2\n",
    "\n",
    "\n",
    "CREDENTIALS_FILE = 'katkov-test-976d3a85df31.json'  #  ← имя скаченного файла с закрытым ключом\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_FILE, \n",
    "                                                               ['https://www.googleapis.com/auth/spreadsheets', \n",
    "                                                                'https://www.googleapis.com/auth/drive'])\n",
    "httpAuth = credentials.authorize(httplib2.Http())\n",
    "\n",
    "# scope = ['https://spreadsheets.google.com/feeds',\n",
    "#          'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "#     'katkov-test-976d3a85df31.json', scope)\n",
    "\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "spreadsheetId = '1-3K9usjWgwA8wcMxtPZcH4xyJ-psQZ3-meR5pau58ZI'\n",
    "wks_name = 'Input_data'\n",
    "d2g.upload(df, spreadsheetId, wks_name, credentials=credentials, row_names=True)\n",
    "\n",
    "spreadsheetId = '1-3K9usjWgwA8wcMxtPZcH4xyJ-psQZ3-meR5pau58ZI'\n",
    "wks_name = 'Output_data'\n",
    "d2g.upload(outdataframe, spreadsheetId, wks_name, credentials=credentials, row_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
